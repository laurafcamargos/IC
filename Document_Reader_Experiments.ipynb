{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurafcamargos/IC/blob/main/Document_Reader_Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-Ls6eJuZOJU"
      },
      "source": [
        "# Document Reader Experiments\n",
        "\n",
        "In Question Answering (QA), queries are run over several documents to extract an answer to user questions, consisting of two main steps: (1) Document Retriever — retrieve the most useful documents that may contain the answer to a given question; (2) Document Reader — a machine reader carefully examines the retrieved documents and frame an answer.\n",
        "\n",
        "In this Jupyter Notebook, we focused on the Document Reader experiments, motivated by the fact that using a good Reader (higher F1) produces a better and more concise response."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNIJkSiBZSEE"
      },
      "source": [
        "---\n",
        "## Setup\n",
        "\n",
        "Packages installation and setups."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au67ibLgZVCb"
      },
      "source": [
        "### Run Configuration\n",
        "\n",
        "Choose the dataset and the Document Reader algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LalmjrULZGq7"
      },
      "outputs": [],
      "source": [
        "import enum\n",
        "\n",
        "class Dataset(enum.Enum):\n",
        "    '''Dataset options'''\n",
        "    SQuAD = 1\n",
        "    AdvQA = 2\n",
        "    DuoRC = 3\n",
        "    QASports = 4\n",
        "\n",
        "class Sports:\n",
        "    BASKETBALL = \"basketball\"\n",
        "    FOOTBALL = \"football\"\n",
        "    SOCCER = \"soccer\"\n",
        "    ALL = None\n",
        "\n",
        "class DocReader:\n",
        "    '''Document Reader options'''\n",
        "    BERT    = \"deepset/bert-base-uncased-squad2\"\n",
        "    RoBERTa = \"deepset/roberta-base-squad2\"\n",
        "    MiniLM  = \"deepset/minilm-uncased-squad2\"\n",
        "    DistilBERT = \"distilbert-base-uncased-distilled-squad\"\n",
        "    ELECTRA = \"deepset/electra-base-squad2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbqKXjSMcezM"
      },
      "outputs": [],
      "source": [
        "# run configuration\n",
        "NUM_K      = 1 # always = 1\n",
        "DATASET    = Dataset.QASports\n",
        "DOC_READER = DocReader.BERT\n",
        "SPORT      = Sports.BASKETBALL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6wDDSutdwAc"
      },
      "source": [
        "### Package Installation\n",
        "\n",
        "Install Haystack and HuggingFace packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1999MLVdt90",
        "outputId": "01c9d8e0-a43f-4390-eaf7-b781fe754dd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Feb  5 00:34:21 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check if you have a GPU running\n",
        "# The code runs in CPU as well\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsRUap4UdxOe",
        "outputId": "c8b5add3-5181-476b-9cec-0c029fb59ee4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m666.4/666.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.2/86.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.7/219.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.6/349.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\n",
            "tensorboard 2.15.1 requires grpcio>=1.48.2, but you have grpcio 1.47.0 which is incompatible.\n",
            "grpcio-status 1.48.2 requires grpcio>=1.48.2, but you have grpcio 1.47.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "farm-haystack 1.8.0 requires huggingface-hub<0.8.0,>=0.5.0, but you have huggingface-hub 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mSilent installation with success!\n"
          ]
        }
      ],
      "source": [
        "# %%capture\n",
        "# Install the Haystack\n",
        "!pip install pip==22.2.2 --quiet\n",
        "!pip install farm-haystack[colab]==1.8.0 --quiet\n",
        "# !pip install git+https://github.com/deepset-ai/haystack.git#egg=farm-haystack[colab]\n",
        "\n",
        "# Install Huggingface\n",
        "!pip install datasets==2.16.1 --quiet\n",
        "!pip install transformers==4.20.1 --quiet\n",
        "!pip install sentence-transformers==2.2.2 --quiet\n",
        "!echo \"Silent installation with success!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "183EAI5bd2Q2"
      },
      "source": [
        "### Logging\n",
        "\n",
        "We configure how logging messages should be displayed and which log level should be used before importing Haystack."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oYx-oJJKdyqE"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "# Setup Haystack logging format\n",
        "logging.basicConfig(format=\"%(levelname)s - %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3nN5vbehUEV"
      },
      "source": [
        "---\n",
        "## Dataset\n",
        "\n",
        "Importing and download the respective dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ2TYqhwhW29"
      },
      "source": [
        "### Abstract Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XhwInJGFhUzd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from abc import ABCMeta, abstractmethod\n",
        "\n",
        "class AbstactDataset(metaclass = ABCMeta):\n",
        "    '''Abstract dataset class'''\n",
        "\n",
        "    def __init__(self):\n",
        "        self.raw_dataset = self.download()\n",
        "        self.df_dataset = self._transform_df()\n",
        "        print(f\"## {self.name} ##\")\n",
        "        print(self.raw_dataset)\n",
        "\n",
        "    def _transform_df(self):\n",
        "        '''Transform dataset in a pd.DataFrame'''\n",
        "        return pd.DataFrame(self.raw_dataset)\n",
        "\n",
        "    @property\n",
        "    @abstractmethod\n",
        "    def name(self):\n",
        "        '''Dataset name'''\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def download(self):\n",
        "        '''Download the dataset'''\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_documents(self):\n",
        "        '''Get the unique documents to store in the Document Store'''\n",
        "        pass\n",
        "\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_validation(self):\n",
        "        '''Get the validation set'''\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-I5zhpEVQHW"
      },
      "source": [
        "### SQuaD Dataset\n",
        "\n",
        "https://huggingface.co/datasets/squad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PpYws_9qIbAZ"
      },
      "outputs": [],
      "source": [
        "import mmh3\n",
        "from datasets import load_dataset\n",
        "from haystack.schema import Label, Document, Answer\n",
        "from haystack.schema import EvaluationResult, MultiLabel\n",
        "\n",
        "class SQuadDataset(AbstactDataset):\n",
        "    '''SQuaD Dataset'''\n",
        "    name = \"SQuaD Dataset\"\n",
        "    _columns = {\n",
        "        \"title\": \"title\",\n",
        "        \"document\": \"context\",\n",
        "        \"question\": \"question\",\n",
        "    }\n",
        "    _metadata = {\n",
        "        \"dataset_id\": \"id\"\n",
        "    }\n",
        "\n",
        "    def download(self):\n",
        "        dataset = load_dataset(\"squad\", split=\"validation\")\n",
        "        return dataset\n",
        "\n",
        "    def get_documents(self):\n",
        "        # Remove duplicated contents\n",
        "        cc = self._columns\n",
        "        dataset_name = f\"{self.name}\"\n",
        "        df = self.df_dataset\n",
        "        df = df.drop_duplicates(subset=[cc[\"title\"], cc[\"document\"]], keep=\"first\")\n",
        "\n",
        "        # Create Haystack Document objects\n",
        "        list_docs = []\n",
        "        for _, row in df.iterrows():\n",
        "            document_id = mmh3.hash128(row[cc[\"document\"]], signed=False)\n",
        "            doc_metadata = {k: row[v] for k,v in self._metadata.items()}\n",
        "            doc_metadata[\"title\"] = row[cc[\"title\"]]\n",
        "            doc_metadata[\"dataset_name\"] = dataset_name\n",
        "            doc = Document(\n",
        "                id=document_id,\n",
        "                content_type=\"text\",\n",
        "                content=row[cc[\"document\"]],\n",
        "                meta=doc_metadata\n",
        "            )\n",
        "            list_docs.append(doc)\n",
        "        return list_docs\n",
        "\n",
        "    def _get_answers(self, data):\n",
        "        # Get question answer\n",
        "        return data[\"answers\"][\"text\"]\n",
        "\n",
        "    def get_validation(self):\n",
        "        # Get dataset info\n",
        "        cc = self._columns\n",
        "        df = self.df_dataset\n",
        "        _self = self\n",
        "\n",
        "        # Create Haystack labels\n",
        "        eval_labels = []\n",
        "        for _, row in df.iterrows():\n",
        "            document_id = mmh3.hash128(row[cc[\"document\"]], signed=False)\n",
        "            doc_label = MultiLabel(labels=[\n",
        "                Label(\n",
        "                    query = row[cc[\"question\"]],\n",
        "                    answer = Answer(answer = answer, type = \"extractive\"),\n",
        "                    document = Document(\n",
        "                        id=document_id,\n",
        "                        content_type=\"text\",\n",
        "                        content=row[cc[\"document\"]],\n",
        "                    ),\n",
        "                    is_correct_answer=True,\n",
        "                    is_correct_document=True,\n",
        "                    origin=\"gold-label\",\n",
        "                )\n",
        "                for answer in _self._get_answers(row)\n",
        "            ])\n",
        "            eval_labels.append(doc_label)\n",
        "        return eval_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwTiflFj4rzz"
      },
      "source": [
        "### AdversarialQA Dataset\n",
        "\n",
        "https://huggingface.co/datasets/adversarial_qa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GBeOsUVq4rg_"
      },
      "outputs": [],
      "source": [
        "class AdversarialQADataset(SQuadDataset):\n",
        "    '''AdversarialQA Dataset'''\n",
        "    name = \"AdversarialQA Dataset\"\n",
        "\n",
        "    def download(self):\n",
        "        dataset = load_dataset(\"adversarial_qa\", \"adversarialQA\", split=\"validation\")\n",
        "        return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9wk72kP69cW"
      },
      "source": [
        "### DuoRC Dataset\n",
        "\n",
        "https://huggingface.co/datasets/duorc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rHHyNQ8j7B-D"
      },
      "outputs": [],
      "source": [
        "class DuoRCDataset(SQuadDataset):\n",
        "    '''DuoRC  Dataset'''\n",
        "    name = \"DuoRC Dataset\"\n",
        "    _columns = {\n",
        "        \"title\": \"title\",\n",
        "        \"document\": \"plot\",\n",
        "        \"question\": \"question\",\n",
        "    }\n",
        "    _metadata = {\n",
        "        \"dataset_id\": \"question_id\"\n",
        "    }\n",
        "\n",
        "    def download(self):\n",
        "        dataset = load_dataset(\"duorc\", \"SelfRC\", split=\"validation\")\n",
        "        return dataset\n",
        "\n",
        "    def _transform_df(self):\n",
        "        '''Transform dataset in a pd.DataFrame'''\n",
        "        df = pd.DataFrame(self.raw_dataset)\n",
        "        # Get questions with answer\n",
        "        return df[~df[\"no_answer\"]]\n",
        "\n",
        "    def _get_answers(self, data):\n",
        "        # Get question answer\n",
        "        return data[\"answers\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icz9gWMA7njZ"
      },
      "source": [
        "### QASports Dataset\n",
        "\n",
        "https://huggingface.co/datasets/PedroCJardim/QASports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uM5Dejhd7mVt"
      },
      "outputs": [],
      "source": [
        "class QASportsDataset(SQuadDataset):\n",
        "    '''QASports  Dataset'''\n",
        "    name = \"QASports Dataset\"\n",
        "    _columns = {\n",
        "        \"title\": \"context_title\",\n",
        "        \"document\": \"context\",\n",
        "        \"question\": \"question\",\n",
        "    }\n",
        "    _metadata = {\n",
        "        \"dataset_id\": \"id_qa\"\n",
        "    }\n",
        "\n",
        "    def __init__(self, sport=None):\n",
        "        self.sport = sport\n",
        "        super().__init__()\n",
        "\n",
        "    def download(self):\n",
        "        dataset = load_dataset(\"PedroCJardim/QASports\", self.sport, split=\"validation\") if self.sport is not None \\\n",
        "                  else load_dataset(\"PedroCJardim/QASports\", split=\"validation\")\n",
        "        return dataset\n",
        "\n",
        "    def _transform_df(self):\n",
        "        '''Transform dataset in a pd.DataFrame'''\n",
        "        df = pd.DataFrame(self.raw_dataset)\n",
        "        # Get questions with answer\n",
        "        df[\"answer\"] = df[\"answer\"].apply(eval)\n",
        "        mask = df[\"answer\"].apply(lambda x: True if x[\"text\"] != \"\" else False)\n",
        "        return df[mask]\n",
        "\n",
        "    def _get_answers(self, data):\n",
        "        # Get question answer\n",
        "        return [data[\"answer\"][\"text\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGC6aaS1VU3d"
      },
      "source": [
        "### Download the dataset\n",
        "\n",
        "Get the dataset and store the documents in the Document Store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Va1Jn6mStXhf"
      },
      "outputs": [],
      "source": [
        "def dataset_switch(choice):\n",
        "    '''Get dataset class'''\n",
        "\n",
        "    if choice == Dataset.SQuAD:\n",
        "        return SQuadDataset()\n",
        "    elif choice == Dataset.AdvQA:\n",
        "        return AdversarialQADataset()\n",
        "    elif choice == Dataset.DuoRC:\n",
        "        return DuoRCDataset()\n",
        "    elif choice == Dataset.QASports:\n",
        "        return QASportsDataset(SPORT)\n",
        "    else:\n",
        "        return \"Invalid dataset\"\n",
        "\n",
        "# Get the dataset\n",
        "dataset = dataset_switch(DATASET)\n",
        "docs = dataset.get_documents()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KA6tLOLhmEF"
      },
      "source": [
        "---\n",
        "## Document Reader\n",
        "\n",
        "In this experiment, we explored three Transformer based models for extractive Question Answering using the [FARM framework](https://github.com/deepset-ai/FARM).\n",
        "* [BERT paper](https://arxiv.org/abs/1810.04805), [implementation](https://huggingface.co/deepset/bert-base-uncased-squad2)\n",
        "* [RoBERTa paper](https://arxiv.org/abs/1907.11692), [implementation](https://huggingface.co/deepset/roberta-base-squad2)\n",
        "* [MiniLM paper](https://arxiv.org/abs/2002.10957), [implementation](https://huggingface.co/deepset/minilm-uncased-squad2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-WqsMnee4Al"
      },
      "outputs": [],
      "source": [
        "from haystack.nodes import FARMReader\n",
        "\n",
        "# Get the reader\n",
        "reader = FARMReader(DOC_READER, use_gpu=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXMO1L8ojvHl"
      },
      "outputs": [],
      "source": [
        "from haystack import Pipeline\n",
        "\n",
        "# Build the pipeline\n",
        "pipe = Pipeline()\n",
        "pipe.add_node(component=reader, name='Reader', inputs=['Query'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6DQcu0-liGN"
      },
      "outputs": [],
      "source": [
        "# Testing the pipeline\n",
        "from haystack.utils import print_answers\n",
        "\n",
        "# Querying documents\n",
        "question = \"When was the anniversary?\"\n",
        "prediction = pipe.run(query=question, documents=docs[0:10], params={\"Reader\": {\"top_k\": 3}})\n",
        "\n",
        "# Print answer\n",
        "print_answers(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuRBbd0Qndmn"
      },
      "source": [
        "---\n",
        "## Evaluation\n",
        "\n",
        "About the metrics, you can read the [evaluation](https://docs.haystack.deepset.ai/docs/evaluation) web page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DewrQrDklo0e"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# For testing purposes, running on the first 100 labels\n",
        "# For real evaluation, you must remove the [0:100]\n",
        "eval_labels = dataset.get_validation()\n",
        "eval_docs = [[label.document for label in multi_label.labels] for multi_label in eval_labels]\n",
        "\n",
        "eval_result = pipe.eval(labels=eval_labels, documents=eval_docs, params={\"Reader\": {\"top_k\": NUM_K}})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9CUdUzungB_"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# Get and print the metrics\n",
        "metrics = eval_result.calculate_metrics()\n",
        "pprint(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjuKxz6XLZ9U"
      },
      "outputs": [],
      "source": [
        "# Print a detailed report\n",
        "# pipe.print_eval_report(eval_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yy8zP8RLbI0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "D6wDDSutdwAc",
        "183EAI5bd2Q2",
        "gQ2TYqhwhW29",
        "x-I5zhpEVQHW",
        "cwTiflFj4rzz",
        "V9wk72kP69cW"
      ],
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}